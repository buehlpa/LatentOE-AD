{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTOENCODER ON EXTRACTED FEATURES workbook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\buehl\\\\Dropbox\\\\ZHAW\\\\MSE_DataScience\\\\23FS\\\\VT2\\\\Anomaly_detection_images\\\\bosch_AD\\\\LatentOE-AD\\\\Additional_Code_BULE', 'c:\\\\Users\\\\buehl\\\\git\\\\projects\\\\LatentOE-AD', 'c:\\\\Users\\\\buehl\\\\anaconda3\\\\envs\\\\AutencoderTF\\\\python39.zip', 'c:\\\\Users\\\\buehl\\\\anaconda3\\\\envs\\\\AutencoderTF\\\\DLLs', 'c:\\\\Users\\\\buehl\\\\anaconda3\\\\envs\\\\AutencoderTF\\\\lib', 'c:\\\\Users\\\\buehl\\\\anaconda3\\\\envs\\\\AutencoderTF', '', 'c:\\\\Users\\\\buehl\\\\anaconda3\\\\envs\\\\AutencoderTF\\\\lib\\\\site-packages', 'c:\\\\Users\\\\buehl\\\\anaconda3\\\\envs\\\\AutencoderTF\\\\lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\buehl\\\\anaconda3\\\\envs\\\\AutencoderTF\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\buehl\\\\anaconda3\\\\envs\\\\AutencoderTF\\\\lib\\\\site-packages\\\\Pythonwin']\n",
      "tensorflow_version: 2.10.1\n",
      "torch_version: 2.0.1\n",
      "Tensorflow: Num GPUs Available:  1\n",
      "GPU for pytorch: True\n"
     ]
    }
   ],
   "source": [
    "#activate conda env AutencoderTF env tf '2.10.0' , python 3.9.16\n",
    "import tensorflow as tf\n",
    "from skimage.metrics import mean_squared_error, normalized_root_mse,normalized_mutual_information\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from alive_progress import  alive_bar\n",
    "import torch\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "print(sys.path)\n",
    "sys.path.append('c:\\\\Users\\\\buehl\\\\Dropbox\\\\ZHAW\\\\MSE_DataScience\\\\23FS\\\\VT2\\\\Anomaly_detection_images\\\\bosch_AD\\\\LatentOE-AD')\n",
    "from loader.LoadData import CIFAR10_feat , FMNIST_feat\n",
    "from Additional_Code_BULE.utils.helper_functions  import *\n",
    "from Additional_Code_BULE.utils.AE_models_TF  import *\n",
    "\n",
    "\n",
    "print(f'tensorflow_version: {tf.__version__}')\n",
    "print(f'torch_version: {torch.__version__}')\n",
    "print(\"Tensorflow: Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(f'GPU for pytorch: {torch.cuda.is_available()}')\n",
    "\n",
    "\n",
    "DATA_PATH=\"C:/Users/buehl/Dropbox/ZHAW/MSE_DataScience/23FS/VT2/Anomaly_detection_images/bosch_AD/LatentOE-AD/DATA/fmnist_features/\"\n",
    "modelname='Autoencoder_features_simple_3'\n",
    "MODEL_SHORT= 'AE3_Refined'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "runs=[0,1,2,3,4]    #list of how many runs \n",
    "all_metrics=False # if True, all metrics are calculated, if False only mse \n",
    "testrun=False\n",
    "\n",
    "\n",
    "labels=[0,1,2,3,4,5,6,7,8,9]\n",
    "contam_list=np.round(np.arange(0,0.5,0.05),2)\n",
    "epochs=10\n",
    "\n",
    "if testrun:\n",
    "    labels=[0]\n",
    "    contam_list=[0.0,0.1]\n",
    "    epochs=1\n",
    "\n",
    "MODEL_RESULT_PATH = Path(f\"C:/Users/buehl/Dropbox/ZHAW/MSE_DataScience/23FS/VT2/Anomaly_detection_images/bosch_AD/LatentOE-AD/RESULTS/fmnist/{MODEL_SHORT}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    with alive_bar(len(runs)*len(labels)*len(contam_list)*10000,force_tty=True) as bar:\n",
    "        #each run creates new samples\n",
    "        for run in runs:\n",
    "            # for every contamination ratio\n",
    "            for contam in contam_list:\n",
    "\n",
    "                nmi,mse,nrmse,csim,msle,normal_label,anomaly,contam_ratio=[],[],[],[],[],[],[],[]\n",
    "\n",
    "                for i in labels:\n",
    "                    # load data for each class\n",
    "                    x_train, y_train, x_test, y_test = FMNIST_feat(i,root=DATA_PATH,contamination_rate=contam)\n",
    "                    x_train=x_train.numpy()\n",
    "                    x_test=x_test.numpy()\n",
    "\n",
    "                    # # transformation of features train\n",
    "                    scaler = MinMaxScaler()\n",
    "                    scaler.fit(x_train)\n",
    "                    x_train=np.sqrt(scaler.transform(x_train))\n",
    "\n",
    "                    # # transformation of features train\n",
    "                    scaler = MinMaxScaler()\n",
    "                    scaler.fit(x_test)\n",
    "                    x_test=np.sqrt(scaler.transform(x_test))\n",
    "                    \n",
    "\n",
    "                    #####  Autoencoder 3\n",
    "                    # instantiate model Autoencoder\n",
    "                    autoencoder = Autoencoder_features_simple_3()\n",
    "                    autoencoder=autoencoder.model()\n",
    "                \n",
    "                    # fit to data\n",
    "                    autoencoder.fit(x_train, x_train,epochs=epochs,shuffle=True,verbose=False)\n",
    "                    decoded_imgs=autoencoder.predict(x_test,verbose=False)\n",
    "\n",
    "                    ##### only for Autoencoder 1\n",
    "                    # #testing on 1000 normal samples and 9000 anomalies per i\n",
    "                    # encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
    "                    # decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
    "\n",
    "                    #reconstruction metrics for vectors\n",
    "                    for j in range(0,len(decoded_imgs)):\n",
    "                        \n",
    "                        if all_metrics:\n",
    "                            #different metrics \n",
    "                            mse.append(mean_squared_error(x_test[j],decoded_imgs[j]))\n",
    "                            csim.append(tf.keras.losses.cosine_similarity(x_test[j],decoded_imgs[j]).numpy())\n",
    "                            msle.append(tf.keras.losses.mean_squared_logarithmic_error(x_test[j],decoded_imgs[j]).numpy())\n",
    "                            nrmse.append(normalized_root_mse(x_test[j],decoded_imgs[j]))\n",
    "                            nmi.append(normalized_mutual_information(x_test[j],decoded_imgs[j])-1)\n",
    "                        else:\n",
    "                            mse.append(mean_squared_error(x_test[j],decoded_imgs[j]))\n",
    "\n",
    "                        # labels ratio and anomaly ratio\n",
    "                        normal_label.append(i)\n",
    "                        anomaly.append(y_test[j])\n",
    "                        contam_ratio.append(contam)\n",
    "                        bar()\n",
    "                if all_metrics:\n",
    "                    df_per_contam =pd.DataFrame({'mse_': mse, 'csim_': csim,'msle_': msle,'nrmse_': nrmse,'normal_label':normal_label,'nmi_':nmi,'anomaly_':anomaly,'contam_ratio':contam_ratio})#,\n",
    "                else:\n",
    "                    df_per_contam =pd.DataFrame({'mse_': mse,'normal_label':normal_label,'anomaly_':anomaly,'contam_ratio':contam_ratio})#,\n",
    "\n",
    "                SAVE_PATH=os.path.join(MODEL_RESULT_PATH,f\"{modelname}_contam_{int(contam*100)}%_run_{run}.pkl\")\n",
    "                df_per_contam.to_pickle(SAVE_PATH)\n",
    "\n",
    "\n",
    "\n",
    "            save_allresults_pickle(MODEL_RESULT_PATH,run=run,name=modelname)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutencoderTF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
